---
layout: post
title: "Java 线程池配置的常见误区"
category: blog
tags: [Java, Thread]
date: 2019-04-20 08:00:06 +0800
comments: true
hidden: true
---

## 前言
---
由于线程的创建和销毁对操作系统来说都是比较重量级的操作，所以线程的池化在各种语言内都有实践，当然在 Java 语言中线程池是也非常重要的一部分，有 Doug Lea 大神对线程池的封装，我们使用的时候是非常方便，但也可能会因为不了解源码，对线程池的配置参数存在误解。

我们经常在一些技术书籍或博客上看到，线程池的使用流程如下：

1. 当一个任务被提交后，线程池首先检正在运行的线程数是否达到核心线程数，如果未达到则创建一个核心线程。
2. 如果线程池内正在运行的线程数已经达到了核心线程数，任务将会被放到 BlockingQueue 内。
3. 如果 BlockingQueue 已满，线程池将会尝试将线程数添加到最大线程池容量。
4. 如果当前线程池内线程数量已经达到最大线程池容量，则会执行拒绝策略拒绝线程的执行。

流程如图（摘自美团技术博客）：

<img src="/images/2020/thread_pool_flow.png"  alt=""/>

流程描述当然没有问题，问题是描述中的某些点如果未经过推敲，容易导致误解。而且描述中的情境太理想化，如果配置时不考虑运行时环境，会出现一些非常诡异的问题。

{{ site.article.copyright }}

## 核心池
---
线程池内线程数量小于等于 coreSize 的部分我称为核心池，核心池是线程池的常驻部分，内部的线程一般不会被销毁，我们提交的任务也应该绝大部分都由核心池内的线程来执行。

### 线程创建时机
有关核心池最常见的一个误区是没搞清楚核心池内线程的创建时机，这个问题，我觉得甩 10% 的锅给 Doug Lea 大神应该不算过分，因为他在文档里写道 "If fewer than corePoolSize threads are running, try to start a new thread with the given command as its first task"，其中 `"running"` 这个词就比较有歧义，因为在我们理解里 running 是指当前线程已被操作系统调度，拥有操作系统时间分片，或者被理解为正在执行某个任务。

基于以上的理解，我们很容易就认为如果任务的 QPS 非常低，线程池内线程数量永远也达不到 coreSize。

即如果我们配置了 coreSize 为 1000，实际上 QPS 只有 1，单个任务耗时 1s，那么核心池大小就会一直是 1，即使有流量抖动，核心池也只会被扩容到 3。因为一个线程每秒执行执行一个任务，刚好不用创建新线程就足以应对 1QPS。

### 创建过程
但如果简单设计一个测试，使用 jstack 打印出线程栈并计算一下线程池内线程数量，会发现线程池内的线程数会随着任务的提交而逐渐增大，直到达到 coreSize。

因为核心池的设计初衷是想它能承载日常流量的峰值，而且作为常驻池，它应该被尽快初始化，所以线程池的逻辑是在没有达到 coreSize 之前，每一个任务都会创建一个新的线程，对应的源码为：

```java
    public void execute(Runnable command) {
        ...
        int c = ctl.get();
        if (workerCountOf(c) < corePoolSize) { // workerCountOf() 方法是获取线程池内线程数量
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        ...
    }
```
而文档里的 running 状态也指的是线程已经被创建，我们也知道线程被创建后，会在一个 while 循环里尝试从 BlockingQueue 里获取并执行任务，说它正在 running 也不为过。

基于此，一些高并发的服务经常会需要预热，其实并不是期望 JVM 能对热点代码做 JIT 等优化，对线程池、连接池和本地缓存的预热才是重点。
## BlockingQueue 
---
BlockingQueue 也是线程池内的一个极重要的组件，它有两个作用：

1. 作为"生产者-消费者"模型的中间媒介；
2. 为大量突发的流量做缓冲。

理解和配置它也经常会出错。
### 运行模型
最常见的错误是不理解线程池的运行模型。首先要明确的一点是线程池并没有准确的调度功能，即它无法感知有哪些线程是处于空闲状态的，并把提交的任务派发给空闲线程。

线程池采用的是"生产者-消费者"模式，除了触发线程创建的任务（线程的 firstTask）不会入 BlockingQueue 外，其他任务都要进入到 BlockingQueue，等待线程池内的线程消费，而任务会被哪个线程消费到完全取决于操作系统的调度。

对应的生产者源码如下：
```java
    public void execute(Runnable command) {
        ...
        if (isRunning(c) && workQueue.offer(command)) { isRunning() 是判断线程池处理戚状态
            int recheck = ctl.get();
            if (! isRunning(recheck) && remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        ...
    }
```

对应的消费者源码如下：

```java
private Runnable getTask() {
        for (;;) {
            ...
            Runnable r = timed ?
                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
                workQueue.take();
            if (r != null)
                return r;
            ...
        }
    }
```
### BlockingQueue 的缓冲作用
基于"生产者-消费者"模型，我们可能会认为如果配置了足够的消费者，是不是线程池就不会有任何问题呢？其实不然，我们还必须考虑并发量这一因素。

我们设想以下情况：有 1000 个任务要提交到线程池内并发执行，在线程池被初始化完成的情况下，它们都要被放到 BlockingQueue 内等待被消费，在极限情况就是这 1000 个请求会被同时放到 BlockingQueue 内，如果配置的 BlockingQueue Size 过小，多余的请求就会被拒绝。

那么这种极限情况发生的概率有多大呢？答案是非常大，因为操作系统对 I/O 线程的调度优先级是非常高的，一般我们的任务都是由 I/O 的完成（如 tomcat 受理了 http 请求）开始的，所以很有可能被调度到的都是 tomcat 线程，它们在一直往线程池内提交请求，而消费者却调度不到，导致请求堆积。

我负责的服务就发生过这种情况，压测 QPS 2000，平均响应时间为 20ms，在线程池 coreSize 为 1000，BlockingQueue Size 为 50 时就频繁出现请求被线程池拒绝。

### 并发量的计算
所以配置线程池时，了解并发量异常重要，因为线程池要能承载得了服务的并发量。并发量是指有多个任务在同时执行，而在上文提到的极限情况下，线程池能支持`BlockingQueue Size`个任务同时提交，所以除了作为"生产者-消费者"的媒介外，BlockingQueue 的另一个重要的意义就是它是一个能长时间存储任务的容器，能以很小的代价为线程池提供缓冲。

我们常用 QPS 来衡量服务压力，所以配置线程池参数时也经常参考这个值，但有时候 QPS 和并发量有时候相关性并没有那么高，QPS 还要`搭配任务执行时间`来`推算`峰值并发量。

比如请求间隔严格相同的接口，平均 QPS 为 1000 的接口，它的并发量峰值是多少呢？我们并没有办法估算，因为如果任务执行时间为 1ms，那么它的并发量只有 1；而如果任务执行时间为 1s，那么并发量峰值为 1000。

可是知道了任务执行时间，就能算出并发量了吗？也不能，因为如果请求的间隔不同，可能 1min 内的请求都在一秒内发过来，那这个并发量还要乘以 60，所以上面才说知道了 QPS 和任务执行时间，并发量也只能靠推算。

## 考虑运行时
---
### GC
除了上面提到的各种情况下，GC 也是一个很重要的影响因素。

我们都知道 GC 是 Stop the World 的，但这里的 World 指的是 JVM，而一个请求 I/O 的准备是操作系统在进行的，所以 GC 是会堆积请求的。

上文中提到的并发量计算一定要考虑到 GC 时间内堆积的请求同时被受理的情况。

### 业务峰值
当然，再完善的服务还是要考虑业务场景的。

假如接口的流量大部分来自于一个定时程序，那么平均 QPS 就没有了任何意义，线程池设计时就要考虑给 BlockingQueue 的 Size 设置一个大一些的值；而如果流量非常不平均，一天内只有某一小段时间才有高流量的话，而且线程资源紧张的情况下，就要考虑给线程池的 maxSize 留下较大的冗余。

当然除了经验和计算外，对服务做定时的压测无疑更能帮助掌握服务的情况。

## 小结
---
总结线程池的配置时，我最大的感受是一定要读源码！读源码！读源码！只看一些书和文章的总结是无法吃透一些重要概念的，即使搞懂了大部分也很容易会在一些角落踩坑。

线程池可讨论的点有很多，本文应该会持续修订，请关注原文。

{{ site.article.summary }}

参考文献：

- [Java线程池实现原理及其在美团业务中的实践](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)


























